{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5385130a-e931-4c9c-a27d-a6115e2f2c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 03_Gold_Aggregation (Secure Version)\n",
    "from pyspark.sql.functions import col, to_date, lit, concat, sum, count, min, max\n",
    "from delta.tables import *\n",
    "\n",
    "# --- 1. CONFIGURATION (SECURE) ---\n",
    "try:\n",
    "    client_id = dbutils.secrets.get(scope=\"kv-secrets\", key=\"sp-client-id\")\n",
    "    client_secret = dbutils.secrets.get(scope=\"kv-secrets\", key=\"sp-client-secret\")\n",
    "    print(\"✅ Secrets retrieved successfully from Key Vault.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error retrieving secrets. Check your Scope Name and Key Names.\")\n",
    "    raise e\n",
    "\n",
    "# Database Config\n",
    "jdbcHostname = \"server-crypto-trades.database.windows.net\"\n",
    "jdbcDatabase = \"db-crypto-trades\"\n",
    "jdbcUrl = f\"jdbc:sqlserver://{jdbcHostname}:1433;database={jdbcDatabase};encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n",
    "\n",
    "connectionProperties = {\n",
    "  \"driver\" : \"com.microsoft.sqlserver.jdbc.SQLServerDriver\",\n",
    "  \"authentication\" : \"ActiveDirectoryServicePrincipal\",\n",
    "  \"userName\" : client_id,\n",
    "  \"password\" : client_secret\n",
    "}\n",
    "\n",
    "# --- 2. HELPER: Pre-Clean Tables ---\n",
    "# We use spark._jvm to access Java classes from Python\n",
    "def execute_sql_cleanup():\n",
    "    print(\"\uD83E\uDDF9 Cleaning SQL Tables (Child -> Parent)...\")\n",
    "    try:\n",
    "        # 1. Get the Driver Manager from JVM\n",
    "        driver_manager = spark._jvm.java.sql.DriverManager\n",
    "        \n",
    "        # 2. Setup Properties for Authentication\n",
    "        props = spark._jvm.java.util.Properties()\n",
    "        props.put(\"user\", client_id)\n",
    "        props.put(\"password\", client_secret)\n",
    "        props.put(\"authentication\", \"ActiveDirectoryServicePrincipal\")\n",
    "        \n",
    "        # 3. Connect and Execute\n",
    "        conn = driver_manager.getConnection(jdbcUrl, props)\n",
    "        stmt = conn.createStatement()\n",
    "        \n",
    "        # Order matters! Delete Fact (Child) first.\n",
    "        stmt.executeUpdate(\"DELETE FROM dbo.Fact_Daily_Market\")\n",
    "        stmt.executeUpdate(\"DELETE FROM dbo.Dim_Exchange\")\n",
    "        stmt.executeUpdate(\"DELETE FROM dbo.Dim_CurrencyPair\")\n",
    "        \n",
    "        conn.close()\n",
    "        print(\"✅ Tables Cleared.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning during cleanup: {e}\")\n",
    "\n",
    "# Run the cleanup immediately\n",
    "execute_sql_cleanup()\n",
    "\n",
    "# --- 3. Read Silver Data ---\n",
    "df_silver = spark.read.table(\"crypto_cat.silver.trades\")\n",
    "\n",
    "# --- 4. LOAD DIMENSION: Exchange ---\n",
    "df_exchanges = df_silver.select(\"exchange\").distinct().withColumnRenamed(\"exchange\", \"ExchangeName\")\n",
    "\n",
    "print(\"Loading Dim_Exchange...\")\n",
    "(df_exchanges.write.jdbc(url=jdbcUrl, table=\"dbo.Dim_Exchange\", mode=\"append\", properties=connectionProperties))\n",
    "\n",
    "# --- 5. LOAD DIMENSION: CurrencyPair ---\n",
    "df_pairs = (df_silver\n",
    "    .select(\"ccy\", \"quoteCcy\")\n",
    "    .distinct()\n",
    "    .withColumn(\"PairName\", concat(col(\"ccy\"), lit(\"-\"), col(\"quoteCcy\")))\n",
    "    .withColumnRenamed(\"ccy\", \"BaseCurrency\")\n",
    "    .withColumnRenamed(\"quoteCcy\", \"QuoteCurrency\")\n",
    ")\n",
    "\n",
    "print(\"Loading Dim_CurrencyPair...\")\n",
    "(df_pairs.write.jdbc(url=jdbcUrl, table=\"dbo.Dim_CurrencyPair\", mode=\"append\", properties=connectionProperties))\n",
    "\n",
    "# --- 6. PREPARE FACT TABLE ---\n",
    "df_agg = (df_silver\n",
    "    .withColumn(\"TradeDate\", to_date(col(\"timestamp\")))\n",
    "    .withColumn(\"PairName\", concat(col(\"ccy\"), lit(\"-\"), col(\"quoteCcy\")))\n",
    "    .groupBy(\"exchange\", \"PairName\", \"TradeDate\")\n",
    "    .agg(\n",
    "        sum(\"qty\").alias(\"TotalVolume\"),\n",
    "        sum(\"quoteQty\").alias(\"TotalValueUSD\"),\n",
    "        count(\"exchange\").alias(\"TradeCount\")\n",
    "    )\n",
    "    .withColumn(\"VWAP\", col(\"TotalValueUSD\") / col(\"TotalVolume\"))\n",
    ")\n",
    "\n",
    "# --- 7. JOIN WITH DIMS (To get IDs) ---\n",
    "# Read back the Dims we just populated to get the SQL-generated IDs\n",
    "dim_exchange_sql = spark.read.jdbc(url=jdbcUrl, table=\"dbo.Dim_Exchange\", properties=connectionProperties)\n",
    "dim_pair_sql = spark.read.jdbc(url=jdbcUrl, table=\"dbo.Dim_CurrencyPair\", properties=connectionProperties)\n",
    "\n",
    "df_fact = (df_agg.alias(\"f\")\n",
    "    .join(dim_exchange_sql.alias(\"e\"), col(\"f.exchange\") == col(\"e.ExchangeName\"))\n",
    "    .join(dim_pair_sql.alias(\"p\"), col(\"f.PairName\") == col(\"p.PairName\"))\n",
    "    .select(\n",
    "        col(\"f.TradeDate\"),\n",
    "        col(\"e.ExchangeID\"),\n",
    "        col(\"p.PairID\"),\n",
    "        col(\"f.TotalVolume\"),\n",
    "        col(\"f.TotalValueUSD\"),\n",
    "        col(\"f.VWAP\"),\n",
    "        col(\"f.TradeCount\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- 8. LOAD FACT TABLE ---\n",
    "print(\"Loading Fact_Daily_Market...\")\n",
    "(df_fact.write.jdbc(url=jdbcUrl, table=\"dbo.Fact_Daily_Market\", mode=\"append\", properties=connectionProperties))\n",
    "\n",
    "print(\"✅ Star Schema Loaded Successfully!\")\n",
    "\n",
    "# COUNT & EXIT (Send Value to ADF)\n",
    "final_count = df_fact.count()\n",
    "print(f\"✅ Job Complete. Rows Loaded: {final_count}\")\n",
    "\n",
    "dbutils.notebook.exit(str(final_count))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Gold_Aggregation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}